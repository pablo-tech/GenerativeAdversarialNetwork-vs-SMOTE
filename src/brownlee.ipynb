{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library: general\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library: randomness\n",
    "\n",
    "import random\n",
    "import scipy \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\"\"\"\n",
    "Result repdoducibility\n",
    "\"\"\"\n",
    "RANDOM_SEED = 0\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.set_random_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCIPY= 1.3.0\n",
      "NUMPY= 1.16.4\n",
      "TENSORFLOW= 1.14.0\n"
     ]
    }
   ],
   "source": [
    "print(\"SCIPY=\", scipy.__version__)\n",
    "print(\"NUMPY=\", np.__version__)\n",
    "print(\"TENSORFLOW=\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1107 20:37:30.787913 140535084832576 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1107 20:37:30.788981 140535084832576 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1107 20:37:30.790681 140535084832576 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1107 20:37:30.833043 140535084832576 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1107 20:37:30.838453 140535084832576 deprecation.py:506] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1107 20:37:30.866560 140535084832576 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1107 20:37:30.870193 140535084832576 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1107 20:37:30.873337 140535084832576 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 real=97% fake=0%\n",
      ">2 real=98% fake=0%\n",
      ">3 real=100% fake=3%\n",
      ">4 real=98% fake=8%\n",
      ">5 real=98% fake=39%\n",
      ">6 real=94% fake=66%\n",
      ">7 real=100% fake=97%\n",
      ">8 real=95% fake=100%\n",
      ">9 real=100% fake=100%\n",
      ">10 real=89% fake=100%\n",
      ">11 real=92% fake=100%\n",
      ">12 real=98% fake=100%\n",
      ">13 real=97% fake=100%\n",
      ">14 real=98% fake=100%\n",
      ">15 real=100% fake=100%\n",
      ">16 real=100% fake=100%\n",
      ">17 real=98% fake=100%\n",
      ">18 real=100% fake=100%\n",
      ">19 real=100% fake=100%\n"
     ]
    }
   ],
   "source": [
    "# example of training the discriminator model on real and random cifar10 images\n",
    "from numpy import expand_dims\n",
    "from numpy import ones\n",
    "from numpy import zeros\n",
    "from numpy.random import rand\n",
    "from numpy.random import randint\n",
    "from keras.datasets.cifar10 import load_data\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    " \n",
    "# define the standalone discriminator model\n",
    "def define_discriminator(in_shape=(32,32,3)):\n",
    "\tmodel = Sequential()\n",
    "\t# normal\n",
    "\tmodel.add(Conv2D(64, (3,3), padding='same', input_shape=in_shape))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# downsample\n",
    "\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# downsample\n",
    "\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# downsample\n",
    "\tmodel.add(Conv2D(256, (3,3), strides=(2,2), padding='same'))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# classifier\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dropout(0.4))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\treturn model\n",
    " \n",
    "# load and prepare cifar10 training images\n",
    "def load_real_samples():\n",
    "\t# load cifar10 dataset\n",
    "\t(trainX, _), (_, _) = load_data()\n",
    "\t# convert from unsigned ints to floats\n",
    "\tX = trainX.astype('float32')\n",
    "\t# scale from [0,255] to [-1,1]\n",
    "\tX = (X - 127.5) / 127.5\n",
    "\treturn X\n",
    " \n",
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "\t# choose random instances\n",
    "\tix = randint(0, dataset.shape[0], n_samples)\n",
    "\t# retrieve selected images\n",
    "\tX = dataset[ix]\n",
    "\t# generate 'real' class labels (1)\n",
    "\ty = ones((n_samples, 1))\n",
    "\treturn X, y\n",
    " \n",
    "# generate n fake samples with class labels\n",
    "def generate_fake_samples(n_samples):\n",
    "\t# generate uniform random numbers in [0,1]\n",
    "\tX = rand(32 * 32 * 3 * n_samples)\n",
    "\t# update to have the range [-1, 1]\n",
    "\tX = -1 + X * 2\n",
    "\t# reshape into a batch of color images\n",
    "\tX = X.reshape((n_samples, 32, 32, 3))\n",
    "\t# generate 'fake' class labels (0)\n",
    "\ty = zeros((n_samples, 1))\n",
    "\treturn X, y\n",
    " \n",
    "# train the discriminator model\n",
    "def train_discriminator(model, dataset, n_iter=20, n_batch=128):\n",
    "\thalf_batch = int(n_batch / 2)\n",
    "\t# manually enumerate epochs\n",
    "\tfor i in range(n_iter):\n",
    "\t\t# get randomly selected 'real' samples\n",
    "\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "\t\t# update discriminator on real samples\n",
    "\t\t_, real_acc = model.train_on_batch(X_real, y_real)\n",
    "\t\t# generate 'fake' examples\n",
    "\t\tX_fake, y_fake = generate_fake_samples(half_batch)\n",
    "\t\t# update discriminator on fake samples\n",
    "\t\t_, fake_acc = model.train_on_batch(X_fake, y_fake)\n",
    "\t\t# summarize performance\n",
    "\t\tprint('>%d real=%.0f%% fake=%.0f%%' % (i+1, real_acc*100, fake_acc*100))\n",
    " \n",
    "# define the discriminator model\n",
    "model = define_discriminator()\n",
    "# load image data\n",
    "dataset = load_real_samples()\n",
    "# fit the model\n",
    "train_discriminator(model, dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
